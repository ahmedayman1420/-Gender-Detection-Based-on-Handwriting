{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import *\n",
    "from COLD import * \n",
    "from LBP import * \n",
    "from HOG import *\n",
    "import pandas as pd\n",
    "from classify import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainDataset=pd.read_csv('NonNormalized.csv')\n",
    "featuresData=mainDataset.iloc[:,3:]\n",
    "mean = featuresData.mean()\n",
    "std = featuresData.std()\n",
    "\n",
    "def predict(imgName, classifier,f):\n",
    "    linesTable = []\n",
    "    linesList = PreprocessImage(imgName,isPrediction=True)\n",
    "    \n",
    "    for line in linesList:\n",
    "        coldHist = ColdFeature(line)\n",
    "        lbpHist = extract_lbp(line)\n",
    "        hogHist = calculateHOG(line)\n",
    "        dataValues = [imgName]\n",
    "        dataValues.extend(coldHist)\n",
    "        dataValues.extend(lbpHist)\n",
    "        dataValues.extend(hogHist)\n",
    "        linesTable.append(dataValues)\n",
    "\n",
    "    COLDLabels = ['COLD_'+str(i) for i in range(100)]\n",
    "    LBPLabels = ['LBP_'+str(i) for i in range(256)]\n",
    "    HOGLabels = ['HOG_'+str(i) for i in range(144)]\n",
    "    labels = ['ImgName']\n",
    "    labels.extend(COLDLabels)\n",
    "    labels.extend(LBPLabels)\n",
    "    labels.extend(HOGLabels)\n",
    "\n",
    "    linesTable = np.array(linesTable)\n",
    "\n",
    "    if(len(linesTable)>0):\n",
    "\n",
    "        df = pd.DataFrame(data=linesTable,columns=labels)\n",
    "\n",
    "        for column in df: \n",
    "            if column != 'Gender' and column != 'ImgName':\n",
    "                df[column] = df[column].astype(float)\n",
    "\n",
    "        #remove columns not found in the normal dataset\n",
    "        for col in df:\n",
    "            if not col in mainDataset.columns:\n",
    "                df=df.drop(columns=[col])\n",
    "\n",
    "        #Calculate standard normalization\n",
    "        df.iloc[:,1:] = df.iloc[:,1:] - mean / std\n",
    "\n",
    "        x_test = np.array(df.iloc[:,1:88])\n",
    "\n",
    "        #Classify here\n",
    "        y_pred = classifier.predict(x_test)\n",
    "        print(y_pred)\n",
    "        y=np.round(np.mean(y_pred))\n",
    "        f.write(str(int(y)))\n",
    "        f.write('\\n')\n",
    "\n",
    "    else:\n",
    "        ### NO LINES FOUND\n",
    "        f.write('1 no lines')\n",
    "        f.write('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output with svm with rbf kernel\n",
      "running time =  10.982125997543335 sec\n"
     ]
    }
   ],
   "source": [
    "x_train, x_valid,y_train,y_valid=read_data('ShuffledData.csv')\n",
    "print('output with svm with rbf kernel')\n",
    "starttime=time.time()\n",
    "accuracies=[]\n",
    "cs=np.arange(0.1,5.1,0.1)\n",
    "for i in cs:\n",
    "    Classifier=classify(x_train,y_train,0,i)\n",
    "    accuracies.append(test(Classifier,x_valid,y_valid))\n",
    "c=cs[accuracies.index(max(accuracies))]\n",
    "\n",
    "Classifier1=classify(x_train,y_train,0,c)\n",
    "print('running time = ',time.time()-starttime,'sec')\n",
    "\n",
    "\n",
    "# X_train, X_test,X_valid,y_valid, y_train, y_test = readData(\"Dataset.csv\")\n",
    "# estimator = get_best_parameter(X_train,y_train,X_valid,y_valid)\n",
    "# regressor = get_Classification(X_train,y_train,estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0.]\n",
      "[0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0.]\n",
      "[0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "[0. 0.]\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "f = open(\"result.txt\", \"w\")\n",
    "f2=open(\"time.txt\",\"w\")\n",
    "        \n",
    "### ENTER FOLDER NAME HERE\n",
    "folderName = 'test'\n",
    "\n",
    "for imgPath in os.listdir(folderName):\n",
    "    starttime=time.time()\n",
    "    predict(folderName+'/'+imgPath,Classifier1,f)\n",
    "    endtime=time.time() \n",
    "    totaltime = endtime - starttime\n",
    "    f2.write(str(round(totaltime, 2)))\n",
    "    f2.write('\\n')\n",
    "f.close()\n",
    "f2.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([1,2,3,4,5])\n",
    "X_train, X_test, y_train, y_test = train_test_split(arr, arr, test_size=0.4,random_state=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "147b12775c70782a669c3e17562f6ad8d6ea3b756fee47049a2c9ad2cf2390b4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
